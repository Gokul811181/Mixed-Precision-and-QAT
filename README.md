# Mixed-Precision-and-QAT
Mixed Precision Training and Quantization Aware Training (QAT) are techniques that optimize deep learning models to improve computational efficiency and reduce memory usage without significant loss in accuracy. Below, we go through the step-by-step process for implementing both .Mixed Precision Training (MPT)
